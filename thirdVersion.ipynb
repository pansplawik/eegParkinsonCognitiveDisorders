{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pansplawik/eegParkinsonCognitiveDisorders/blob/master/thirdVersion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lrrMlniCLSv"
      },
      "outputs": [],
      "source": [
        "!pip install mne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97For1s_Fsq4"
      },
      "source": [
        "Importowanie pakietów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bZB5mF1GXs_"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import csv\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from mne.decoding import PSDEstimator\n",
        "from autoreject import AutoReject\n",
        "from mne.decoding import Vectorizer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "# Models\n",
        "from sklearn import svm\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpF05ty2F_NG"
      },
      "source": [
        "Ściezki plików"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-2GW3L7HmgA"
      },
      "outputs": [],
      "source": [
        "labels = pd.read_csv('/content/drive/MyDrive/dyplom/dataset.csv', sep=';')\n",
        "labels['PD'] = labels['PD'].replace(2, 1)\n",
        "for a in labels['ID']:\n",
        "  print(a)\n",
        "path='/content/drive/MyDrive/dyplom/EEG'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_G_foTfOcTi"
      },
      "source": [
        "Preprocesing danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFYrK-G8Hwy5"
      },
      "outputs": [],
      "source": [
        "def load_epochs_from_dir(path, labels):\n",
        "    epochs_array = []\n",
        "    liczba=1\n",
        "    filenames = sorted(os.listdir(path))\n",
        "    for filename, label in zip(filenames, labels['PD']):\n",
        "        print(filename)\n",
        "        if filename.endswith('.edf'):\n",
        "            filepath = os.path.join(path, filename)\n",
        "            raw = mne.io.read_raw_edf(filepath, preload=True)\n",
        "            raw.info.set_montage('standard_1020')\n",
        "            raw.info['bads'].append('Oz')\n",
        "            annotations = raw.annotations\n",
        "            for i in range(len(annotations)):\n",
        "              if annotations.description[i] == \"break\":\n",
        "                annotations.description[i] = \"BAD\" \n",
        "              elif annotations.description[i] == 'Break end':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "              elif annotations.description[i] == 'Miesnie':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "              elif annotations.description[i] == 'Break start':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "              elif annotations.description[i] == 'Ruch':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "            raw.set_annotations(annotations)\n",
        "            raw.filter(1,40, fir_design='firwin')\n",
        "            events = mne.make_fixed_length_events(raw, duration=1.0)\n",
        "            reject = dict(     \n",
        "              eeg=82e-6,       \n",
        "              )\n",
        "            epochs = mne.Epochs(raw, events, tmin=0, tmax=2, baseline=(0,2), detrend=1,preload=True,reject_by_annotation='BAD',reject=reject)\n",
        "            epochs_array.append([epochs,label])\n",
        "            # try:\n",
        "            #   epochs = ar.fit_transform(epochs)\n",
        "            #   epochs_array.append([epochs,label])  \n",
        "            # except Exception as e:\n",
        "            #   print(\"Wystąpił wyjątek podczas przetwarzania danych:\", e) \n",
        "            del epochs\n",
        "            del raw\n",
        "            del annotations\n",
        "    return epochs_array\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_epochs_from_dir(path, labels):\n",
        "    epochs_array = []\n",
        "    liczba=1\n",
        "    filenames = sorted(os.listdir(path))\n",
        "    for filename, label in zip(filenames, labels['PD']):\n",
        "      print(filename)\n",
        "      if filename.endswith('.edf'):\n",
        "        filepath = os.path.join(path, filename)\n",
        "        raw = mne.io.read_raw_edf(filepath, preload=True)\n",
        "        raw.info.set_montage('standard_1020')\n",
        "        raw.info['bads'].append('Oz')\n",
        "        annotations = raw.annotations\n",
        "        for i in range(len(annotations)):\n",
        "            if annotations.description[i] == \"break\":\n",
        "                annotations.description[i] = \"BAD\" \n",
        "            elif annotations.description[i] == 'Break end':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "            elif annotations.description[i] == 'Miesnie':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "            elif annotations.description[i] == 'Break start':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "            elif annotations.description[i] == 'Ruch':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "        raw.set_annotations(annotations)\n",
        "        raw.filter(1, 40, fir_design='firwin')\n",
        "        events = mne.make_fixed_length_events(raw, duration=1.0)\n",
        "        unique_events, unique_indices = np.unique(events[:, 0], return_index=True)\n",
        "        events = events[unique_indices]\n",
        "        tmin = 0\n",
        "        tmax = 2\n",
        "        baseline = (0, 2)\n",
        "        reject = dict(     \n",
        "              eeg=80e-6,       \n",
        "              )\n",
        "        epochs = mne.Epochs(raw, events, event_id=None, tmin=tmin, tmax=tmax, baseline=baseline, preload=True,reject_by_annotation='BAD',reject=reject)\n",
        "        epochs_array.append([epochs, label])\n",
        "        \n",
        "        del raw\n",
        "        del annotations\n",
        "    return epochs_array\n"
      ],
      "metadata": {
        "id": "xIFLo1uFs43y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEQbQnt-OgNT"
      },
      "source": [
        "PSD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "fQGQh0HcH1FC"
      },
      "outputs": [],
      "source": [
        "def psds(epochs_array, labels):\n",
        "    data = []\n",
        "    for epochs, label in zip(epochs_array, labels):\n",
        "        if epochs is not None and len(epochs) > 0:\n",
        "            epochs_data = epochs.get_data()\n",
        "            epo_spectrum = mne.time_frequency.psd_array_multitaper(epochs_data, 100, fmin=0, fmax=40, bandwidth=4, adaptive=True, normalization='length', output='power', n_jobs=-1, max_iter=100, verbose=True)\n",
        "            psds_epoch, freqs = epo_spectrum\n",
        "            for p in psds_epoch:\n",
        "                p = 10 * np.log10(p)\n",
        "                psds_mean = p.mean(0)\n",
        "                psds_std = p.std(0)\n",
        "                data.append([p, label])\n",
        "            del psds_epoch\n",
        "            del freqs\n",
        "            del epo_spectrum\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2zeLSloH7lT"
      },
      "outputs": [],
      "source": [
        "data = load_epochs_from_dir('/content/drive/MyDrive/dyplom/EEG',labels)\n",
        "df = pd.DataFrame(data, columns=['value', 'label'])\n",
        "df.to_csv('data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s2p99fgQIx1"
      },
      "outputs": [],
      "source": [
        "psd = psds([epochs for epochs, label in data], [label for epochs, label in data])\n",
        "df = pd.DataFrame(psd, columns=['psds', 'label'])\n",
        "df.to_csv('psd.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iedCL3MEOjR-"
      },
      "source": [
        "Tworzenie zestawów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "_1N_sb4dMXDQ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['psds'], df['label'], test_size=0.1, random_state=42)\n",
        "X_train_2d = np.array([x[0] for x in X_train]).reshape(len(X_train), -1)\n",
        "X_test_2d = np.array([x[0] for x in X_test]).reshape(len(X_test), -1)\n",
        "y_train=np.array(y_train)\n",
        "y_train=y_train.transpose()\n",
        "y_test=np.array(y_test)\n",
        "y_test=y_test.transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw0tezpXmArB",
        "outputId": "af30dcaf-52a0-486d-b3cb-463730fa4a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      3595\n",
            "           1       0.86      0.82      0.84      3528\n",
            "\n",
            "    accuracy                           0.84      7123\n",
            "   macro avg       0.85      0.84      0.84      7123\n",
            "weighted avg       0.85      0.84      0.84      7123\n",
            "\n",
            "Accuracy of SVM model: 0.8448687350835322\n",
            "Precision: 0.8456614793838524, Recall: 0.8446397427770367, F1-score: 0.844706821918905\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "# Tworzenie i trenowanie modelu SVM\n",
        "clf_svm_pip = make_pipeline(Vectorizer(), StandardScaler(), SVC())\n",
        "clf_svm_pip.fit(X_train_2d, y_train)\n",
        "\n",
        "# Przewidywanie etykiet dla danych testowych\n",
        "predictions_svm = clf_svm_pip.predict(X_test_2d)\n",
        "\n",
        "# Raport klasyfikacji\n",
        "report_svm = classification_report(y_test, predictions_svm, target_names=['0', '1'])\n",
        "print('SVM Classification Report:\\n{}'.format(report_svm))\n",
        "\n",
        "# Dokładność modelu SVM\n",
        "acc_svm = accuracy_score(y_test, predictions_svm)\n",
        "print(\"Accuracy of SVM model: {}\".format(acc_svm))\n",
        "\n",
        "# Obliczanie precyzji, czułości i miary F1\n",
        "precision_svm, recall_svm, fscore_svm, support_svm = precision_recall_fscore_support(y_test, predictions_svm, average='macro')\n",
        "print('Precision: {0}, Recall: {1}, F1-score: {2}'.format(precision_svm, recall_svm, fscore_svm))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Vectorizer(),\n",
        "    RandomForestClassifier()  # Używamy Random Forest z domyślnymi parametrami\n",
        ")\n",
        "clf.fit(X_train_2d, y_train)\n",
        "\n",
        "# Przewidywanie etykiet dla danych testowych\n",
        "y_pred = clf.predict(X_test_2d)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy score: {}\".format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT3tXm-BccPv",
        "outputId": "22e46601-d7bc-4280-ee73-2174ab27bf38"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.9785202863961814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = make_pipeline(\n",
        "StandardScaler(),\n",
        "Vectorizer(),\n",
        "LogisticRegression() # Używamy regresji logistycznej z domyślnymi parametrami\n",
        ")\n",
        "clf.fit(X_train_2d, y_train)\n",
        "\n",
        "#Przewidywanie etykiet dla danych testowych\n",
        "y_pred = clf.predict(X_test_2d)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy score: {}\".format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOM-MW9JrDO4",
        "outputId": "159cd452-057d-4e58-f3e9-6b8983d75346"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.6998455706865085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWGtg5RqGVc3",
        "outputId": "c7506d95-ce8e-40b5-bd58-2c8ab2f05ff7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oficjalnyRandomForest.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "from joblib import dump, load\n",
        "dump(clf, 'oficjalnyRandomForest.joblib') "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1Szo-64AjzluEasu8zzcDW_-gO3xfmujY",
      "authorship_tag": "ABX9TyO5T+opbkUW3g6oAT/jV2Nz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}