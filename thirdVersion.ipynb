{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pansplawik/eegParkinsonCognitiveDisorders/blob/master/thirdVersion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lrrMlniCLSv"
      },
      "outputs": [],
      "source": [
        "!pip install mne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97For1s_Fsq4"
      },
      "source": [
        "Importowanie pakietów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8bZB5mF1GXs_"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpF05ty2F_NG"
      },
      "source": [
        "Ściezki plików"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a-2GW3L7HmgA"
      },
      "outputs": [],
      "source": [
        "labels = pd.read_csv('/content/drive/MyDrive/dyplom/dataset.csv', sep=';')\n",
        "labels['PD'] = labels['PD'].replace(2, 1)\n",
        "path='/content/drive/MyDrive/dyplom/EEG'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_G_foTfOcTi"
      },
      "source": [
        "Preprocesing danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xIFLo1uFs43y"
      },
      "outputs": [],
      "source": [
        "def load_epochs_from_dir(path, labels):\n",
        "    epochs_array = []\n",
        "    liczba=1\n",
        "    filenames = sorted(os.listdir(path))\n",
        "    for filename, label in zip(filenames, labels['PD']):\n",
        "      print(filename)\n",
        "      if filename.endswith('.edf'):\n",
        "        filepath = os.path.join(path, filename)\n",
        "        raw = mne.io.read_raw_edf(filepath, preload=True,verbose=False)\n",
        "        raw.info.set_montage('standard_1020')\n",
        "        raw.info['bads'].append('Oz')\n",
        "        annotations = raw.annotations\n",
        "        for i in range(len(annotations)):\n",
        "            if annotations.description[i] == \"break\":\n",
        "                annotations.description[i] = \"BAD\"\n",
        "            elif annotations.description[i] == 'Break end':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "            elif annotations.description[i] == 'Miesnie':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "            elif annotations.description[i] == 'Break start':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "            elif annotations.description[i] == 'Ruch':\n",
        "                annotations.description[i] = \"BAD\"\n",
        "        raw.set_annotations(annotations)\n",
        "        raw.filter(1, 40, fir_design='firwin')\n",
        "        events = mne.make_fixed_length_events(raw, duration=1.0)\n",
        "        unique_events, unique_indices = np.unique(events[:, 0], return_index=True)\n",
        "        events = events[unique_indices]\n",
        "        tmin = 0\n",
        "        tmax = 2\n",
        "        baseline = (0, 2)\n",
        "        reject = dict(\n",
        "              eeg=80e-6,\n",
        "              )\n",
        "        epochs = mne.Epochs(raw, events, event_id=None, tmin=tmin, tmax=tmax, baseline=baseline, preload=True,reject_by_annotation='BAD',reject=reject,verbose=False)\n",
        "        epochs_array.append([epochs, label])\n",
        "        del raw\n",
        "        del annotations\n",
        "    return epochs_array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEQbQnt-OgNT"
      },
      "source": [
        "PSD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "fQGQh0HcH1FC"
      },
      "outputs": [],
      "source": [
        "def psds(epochs_array, labels):\n",
        "    data = []\n",
        "    for epochs, label in zip(epochs_array, labels):\n",
        "        if epochs is not None and len(epochs) > 0:\n",
        "            epochs_data = epochs.get_data()\n",
        "            epo_spectrum = mne.time_frequency.psd_array_multitaper(epochs_data, 512, fmin=1, fmax=4, bandwidth=4, adaptive=True, normalization='length', output='power', n_jobs=-1, max_iter=100, verbose=False)\n",
        "            psds_epoch, freqs = epo_spectrum\n",
        "            combined_psds = []\n",
        "            for p in psds_epoch:\n",
        "                p = 10 * np.log10(p)\n",
        "                psds_mean = p.mean(0)\n",
        "                psds_std = p.std(0)\n",
        "                combined_psds.append(psds_mean)\n",
        "            combined_psds = np.array(combined_psds)\n",
        "            data.append([combined_psds, label])\n",
        "\n",
        "            del psds_epoch\n",
        "            del freqs\n",
        "            del epo_spectrum\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2zeLSloH7lT"
      },
      "outputs": [],
      "source": [
        "data = load_epochs_from_dir('/content/drive/MyDrive/dyplom/EEG',labels)\n",
        "df = pd.DataFrame(data, columns=['value', 'label'])\n",
        "df.to_csv('data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3s2p99fgQIx1"
      },
      "outputs": [],
      "source": [
        "psd = psds([epochs for epochs, label in data], [label for epochs, label in data])\n",
        "df = pd.DataFrame(psd, columns=['psds', 'label'])\n",
        "df.to_csv('psd.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iedCL3MEOjR-"
      },
      "source": [
        "Tworzenie zestawów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_1N_sb4dMXDQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['psds'], df['label'], test_size=0.1, random_state=42)\n",
        "X_train_2d = np.array([x[0] for x in X_train]).reshape(len(X_train), -1)\n",
        "X_test_2d = np.array([x[0] for x in X_test]).reshape(len(X_test), -1)\n",
        "y_train=np.array(y_train)\n",
        "y_train=y_train.transpose()\n",
        "y_test=np.array(y_test)\n",
        "y_test=y_test.transpose()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train_2d))\n",
        "print(len(y_train))\n",
        "a=1;\n",
        "for p in X_train_2d:\n",
        "  print(a)\n",
        "  a=a+1\n",
        "  print((p))"
      ],
      "metadata": {
        "id": "g9E7_TKwTmla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Jw0tezpXmArB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cce9a9c-ba89-49c0-d446-cfbb586ad7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.75      0.86         4\n",
            "           1       0.88      1.00      0.93         7\n",
            "\n",
            "    accuracy                           0.91        11\n",
            "   macro avg       0.94      0.88      0.90        11\n",
            "weighted avg       0.92      0.91      0.91        11\n",
            "\n",
            "Accuracy of SVM model: 0.9090909090909091\n",
            "Precision: 0.9375, Recall: 0.875, F1-score: 0.8952380952380952\n",
            "Cross-Validation Results (5-fold)\n",
            "Mean Accuracy: 0.5210526315789473\n",
            "Standard Deviation: 0.1057881644328515\n"
          ]
        }
      ],
      "source": [
        "from mne.decoding import Vectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Tworzenie i trenowanie modelu SVM\n",
        "clf_svm_pip = make_pipeline(Vectorizer(), StandardScaler(), SVC())\n",
        "clf_svm_pip.fit(X_train_2d, y_train)\n",
        "\n",
        "# Przewidywanie etykiet dla danych testowych\n",
        "predictions_svm = clf_svm_pip.predict(X_test_2d)\n",
        "\n",
        "# Raport klasyfikacji\n",
        "report_svm = classification_report(y_test, predictions_svm, target_names=['0', '1'])\n",
        "print('SVM Classification Report:\\n{}'.format(report_svm))\n",
        "\n",
        "# Dokładność modelu SVM\n",
        "acc_svm = accuracy_score(y_test, predictions_svm)\n",
        "print(\"Accuracy of SVM model: {}\".format(acc_svm))\n",
        "\n",
        "# Obliczanie precyzji, czułości i miary F1\n",
        "precision_svm, recall_svm, fscore_svm, support_svm = precision_recall_fscore_support(y_test, predictions_svm, average='macro')\n",
        "print('Precision: {0}, Recall: {1}, F1-score: {2}'.format(precision_svm, recall_svm, fscore_svm))\n",
        "\n",
        "# Walidacja krzyżowa z k-fold\n",
        "k = 5  # Liczba podziałów\n",
        "scores = cross_val_score(clf_svm_pip, X_train_2d, y_train, cv=k, scoring='accuracy')\n",
        "\n",
        "\n",
        "# Obliczanie średniej i odchylenia standardowego z poszczególnych iteracji\n",
        "mean_accuracy = scores.mean()\n",
        "std_accuracy = scores.std()\n",
        "\n",
        "print('Cross-Validation Results ({}-fold)'.format(k))\n",
        "print('Mean Accuracy:', mean_accuracy)\n",
        "print('Standard Deviation:', std_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT3tXm-BccPv",
        "outputId": "bee56794-085c-4603-b564-7603499d3e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.75      0.67         4\n",
            "           1       0.83      0.71      0.77         7\n",
            "\n",
            "    accuracy                           0.73        11\n",
            "   macro avg       0.72      0.73      0.72        11\n",
            "weighted avg       0.75      0.73      0.73        11\n",
            "\n",
            "Accuracy of model: 0.7272727272727273\n",
            "Cross-Validation Results (5-fold)\n",
            "Mean Accuracy: 0.5099415204678361\n",
            "Standard Deviation: 0.057345734138625815\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mne.decoding import Vectorizer\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Definiowanie modelu\n",
        "clf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Vectorizer(),\n",
        "    RandomForestClassifier()\n",
        ")\n",
        "# Trenowanie modelu na wszystkich danych treningowych\n",
        "clf.fit(X_train_2d, y_train)\n",
        "\n",
        "# Przewidywanie etykiet dla danych testowych\n",
        "y_pred = clf.predict(X_test_2d)\n",
        "\n",
        "# Raport klasyfikacji\n",
        "report = classification_report(y_test, y_pred, target_names=['0', '1'])\n",
        "print('Random Forest Classification Report:\\n{}'.format(report))\n",
        "\n",
        "# Dokładność modelu\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of model: {}\".format(acc))\n",
        "\n",
        "# Walidacja krzyżowa z k-fold\n",
        "k = 5  # Liczba podziałów\n",
        "scores = cross_val_score(clf, X_train_2d, y_train, cv=k, scoring='accuracy')\n",
        "\n",
        "\n",
        "# Obliczanie średniej i odchylenia standardowego z poszczególnych iteracji\n",
        "mean_accuracy = scores.mean()\n",
        "std_accuracy = scores.std()\n",
        "\n",
        "print('Cross-Validation Results ({}-fold)'.format(k))\n",
        "print('Mean Accuracy:', mean_accuracy)\n",
        "print('Standard Deviation:', std_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOM-MW9JrDO4",
        "outputId": "844d1856-b772-449c-e980-ebe3f0a28dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.5454545454545454\n",
            "Cross-Validation Results (5-fold)\n",
            "Mean Accuracy: 0.5426900584795321\n",
            "Standard Deviation: 0.06992156808250351\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mne.decoding import Vectorizer\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "clf = make_pipeline(\n",
        "StandardScaler(),\n",
        "Vectorizer(),\n",
        "LogisticRegression() # Używamy regresji logistycznej z domyślnymi parametrami\n",
        ")\n",
        "clf.fit(X_train_2d, y_train)\n",
        "\n",
        "#Przewidywanie etykiet dla danych testowych\n",
        "y_pred = clf.predict(X_test_2d)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy score: {}\".format(acc))\n",
        "# Walidacja krzyżowa z k-fold\n",
        "k = 5  # Liczba podziałów\n",
        "scores = cross_val_score(clf, X_train_2d, y_train, cv=k, scoring='accuracy')\n",
        "\n",
        "\n",
        "# Obliczanie średniej i odchylenia standardowego z poszczególnych iteracji\n",
        "mean_accuracy = scores.mean()\n",
        "std_accuracy = scores.std()\n",
        "\n",
        "print('Cross-Validation Results ({}-fold)'.format(k))\n",
        "print('Mean Accuracy:', mean_accuracy)\n",
        "print('Standard Deviation:', std_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWGtg5RqGVc3",
        "outputId": "c7506d95-ce8e-40b5-bd58-2c8ab2f05ff7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['oficjalnyRandomForest.joblib']"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from joblib import dump, load\n",
        "dump(clf, 'oficjalnyRandomForest.joblib')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1Szo-64AjzluEasu8zzcDW_-gO3xfmujY",
      "authorship_tag": "ABX9TyPVn/1tisLxofCTxldUCTRP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}